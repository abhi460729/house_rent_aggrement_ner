{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import\n",
    "import os\n",
    "import docxpy\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import spacy \n",
    "  \n",
    "nlp = spacy.load('en_core_web_sm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = pd.read_csv(\"../data/TrainingTestSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique files in training dataframe: 55\n",
      "Total unique files in docx fmrat: 43\n"
     ]
    }
   ],
   "source": [
    "# find file which are present in training dataframe and folder (in docs format)\n",
    "present, absent = [], []\n",
    "for index, file_name in enumerate(tdf['File Name'].values):\n",
    "    file_path = fr\"../data/Training_data/{file_name}.pdf.docx\"\n",
    "    if os.path.exists(file_path):\n",
    "        present.append((index, file_path))\n",
    "    else:\n",
    "        absent.append(file_path)\n",
    "print(f\"Total unique files in training dataframe: {tdf['File Name'].nunique()}\")\n",
    "print(f\"Total unique files in docx fmrat: {len(set(present))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Aggrement Value</th>\n",
       "      <th>Aggrement Start Date</th>\n",
       "      <th>Aggrement End Date</th>\n",
       "      <th>Renewal Notice (Days)</th>\n",
       "      <th>Party One</th>\n",
       "      <th>Party Two</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6683127-House-Rental-Contract-GERALDINE-GALINA...</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>20.05.2007</td>\n",
       "      <td>20.05.2008</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Antonio Levy S. Ingles, Jr. and/or Mary Rose C...</td>\n",
       "      <td>GERALDINE Q. GALINATO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6683129-House-Rental-Contract-Geraldine-Galina...</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>20.05.2007</td>\n",
       "      <td>20.05.2008</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Antonio Levy S. Ingles, Jr. and/or Mary Rose C...</td>\n",
       "      <td>GERALDINE Q. GALINATO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18325926-Rental-Agreement-1</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>05.12.2008</td>\n",
       "      <td>31.11.2009</td>\n",
       "      <td>90.0</td>\n",
       "      <td>MR.K.Kuttan</td>\n",
       "      <td>P.M. Narayana Namboodri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36199312-Rental-Agreement</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>01.05.2010</td>\n",
       "      <td>31.04.2011</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Balaji.R</td>\n",
       "      <td>Kartheek R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>44737744-Maddireddy-Bhargava-Reddy-Rental-Agre...</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>20.09.2010</td>\n",
       "      <td>19.07.2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M.V.V. VIJAYA SHANKAR</td>\n",
       "      <td>MADDIREDDY BHARGAVA REDDY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            File Name  Aggrement Value  \\\n",
       "8   6683127-House-Rental-Contract-GERALDINE-GALINA...           6500.0   \n",
       "9   6683129-House-Rental-Contract-Geraldine-Galina...           6500.0   \n",
       "10                        18325926-Rental-Agreement-1           4000.0   \n",
       "12                          36199312-Rental-Agreement           3800.0   \n",
       "13  44737744-Maddireddy-Bhargava-Reddy-Rental-Agre...           3000.0   \n",
       "\n",
       "   Aggrement Start Date Aggrement End Date  Renewal Notice (Days)  \\\n",
       "8            20.05.2007         20.05.2008                   15.0   \n",
       "9            20.05.2007         20.05.2008                   15.0   \n",
       "10           05.12.2008         31.11.2009                   90.0   \n",
       "12           01.05.2010         31.04.2011                   30.0   \n",
       "13           20.09.2010         19.07.2011                    NaN   \n",
       "\n",
       "                                            Party One  \\\n",
       "8   Antonio Levy S. Ingles, Jr. and/or Mary Rose C...   \n",
       "9   Antonio Levy S. Ingles, Jr. and/or Mary Rose C...   \n",
       "10                                       MR.K.Kuttan    \n",
       "12                                          Balaji.R    \n",
       "13                              M.V.V. VIJAYA SHANKAR   \n",
       "\n",
       "                    Party Two  \n",
       "8       GERALDINE Q. GALINATO  \n",
       "9       GERALDINE Q. GALINATO  \n",
       "10   P.M. Narayana Namboodri   \n",
       "12                 Kartheek R  \n",
       "13  MADDIREDDY BHARGAVA REDDY  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = [i for i, _ in present]\n",
    "tdf.iloc[indices].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = docxpy.process(\"../data/Training_data/6683127-House-Rental-Contract-GERALDINE-GALINATO-v2-Page-1.pdf.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## for all training data, extract and save the txt files\n",
    "# for present_file in present:\n",
    "#     text = docxpy.process(present_file[1])\n",
    "#     new_file_path = present_file[1].replace(\"Training_data\", \"Training_data_text\") + '.txt'\n",
    "#     with open(new_file_path, \"wb\") as f:\n",
    "#         f.write(text.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run NER on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n"
     ]
    }
   ],
   "source": [
    "def print_all_entities(text_string):\n",
    "    doc = nlp(text_string) \n",
    "    for ent in doc.ents: \n",
    "        print(ent.text, ent.start_char, ent.end_char, ent.label_) \n",
    "        \n",
    "sentence = \"Apple is looking at buying U.K. startup for $1 billion\"\n",
    "print_all_entities(sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000.0 --best match--> 01-09-2011\n",
      "01.09.2011 --best match--> 01-09-2011\n",
      "31.08.2012 --best match--> 01-09-2011\n",
      "nan --best match--> Tenant\n",
      "s parthasarathy --best match--> S Parthasarathy\n",
      "hari kiran tholeti --best match--> Hari Kiran Tholeti\n"
     ]
    }
   ],
   "source": [
    "# find most macthing phrase -- not working !!\n",
    "import difflib\n",
    "index = 14\n",
    "for x in tdf.iloc[present[index][0]].values[1:]:\n",
    "    x=str(x).lower()\n",
    "    best_match_score, best_match = 0, None\n",
    "    text = docxpy.process(present[index][1])\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        match_score = difflib.SequenceMatcher(None, ent.text.lower(), x).ratio()\n",
    "#         print(match_score)\n",
    "        if match_score > best_match_score:\n",
    "            best_match_score = match_score\n",
    "            best_match = ent\n",
    "    print(x, \"--best match-->\", best_match)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_all_entities(text)\n",
    "# difflib.SequenceMatcher(None, ent.text.lower()).ratio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read txt file and extract new annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../data/Training_data_text/100999172-House-Rental-Agreement.pdf.docx.txt\", \"r\") as f:\n",
    "#     text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from glob import glob\n",
    "\n",
    "new_labels = ['[start]', '[partyone]', '[partytwo]', '[rent]', '[end]', '[duration]']\n",
    "def clean_text(text_str):\n",
    "    for word in ['[start]', '[partyone]', '[partytwo]', '[rent]', '[end]', '[duration]', '{{', \"}}\"]:\n",
    "        text_str = text_str.replace(word, \"\")\n",
    "    return text_str\n",
    "\n",
    "def get_training_example(text):\n",
    "    training_example = []\n",
    "    offset = 0\n",
    "    for m in re.compile(\"{{.*?}}\\[.*?\\]\").finditer(text):\n",
    "    #     print(m.start(), m.group())\n",
    "        start = m.start() - offset\n",
    "        val = re.findall(\"{{.*?}}\", m.group())[0]\n",
    "        val_type = re.findall(\"\\[.*?\\]\", m.group())[0]\n",
    "        offset += 4 + 2 + len(val_type) - 2 \n",
    "        end = start + len(val) - 4\n",
    "        training_example.append((start, end, clean_text(val), val_type))\n",
    "    return training_example, clean_text(text)\n",
    "\n",
    "# run on all files, and only keep the ones which have training examples\n",
    "all_training_examples = []\n",
    "for file_path in glob(\"../data/Training_data_text/*\"):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        text = str(f.read(), \"utf-8\")\n",
    "    try:\n",
    "        example = get_training_example(text)\n",
    "    except Exception as e:\n",
    "        example = None\n",
    "    if example is not None:\n",
    "        all_training_examples.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_training_examples = [x for x in all_training_examples if len(x[0])>0]\n",
    "len(all_training_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to training format\n",
    "TRAIN_DATA = []\n",
    "for exs in all_training_examples:\n",
    "    entities = [(ex[0], ex[1], ex[3]) for ex in exs[0]]\n",
    "    TRAIN_DATA.append((exs[1], {\"entities\": entities}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training NER model\n",
    "\n",
    "source: https://www.machinelearningplus.com/nlp/training-custom-ner-model-in-spacy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-existing spacy model\n",
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "\n",
    "# Getting the pipeline component\n",
    "ner=nlp.get_pipe(\"ner\")\n",
    "\n",
    "# Add the new label to ner\n",
    "for label in new_labels:\n",
    "    ner.add_label(label)\n",
    "\n",
    "# Resume training\n",
    "optimizer = nlp.resume_training()\n",
    "move_names = list(ner.move_names)\n",
    "\n",
    "# List of pipes you want to train\n",
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "\n",
    "# List of pipes which should remain unaffected in training\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 3571.4237965345383}\n",
      "Losses {'ner': 3713.9285621643066}\n",
      "Losses {'ner': 3754.075963616371}\n",
      "Losses {'ner': 3521.357950389385}\n",
      "Losses {'ner': 3571.2368539869785}\n",
      "Losses {'ner': 3538.9948283433914}\n",
      "Losses {'ner': 3517.101459145546}\n",
      "Losses {'ner': 3495.333559989929}\n",
      "Losses {'ner': 3512.6860406398773}\n",
      "Losses {'ner': 3398.659801006317}\n",
      "Losses {'ner': 3455.871994972229}\n",
      "Losses {'ner': 3297.037729024887}\n",
      "Losses {'ner': 3543.8431801199913}\n",
      "Losses {'ner': 3533.6909601688385}\n",
      "Losses {'ner': 3506.3521909713745}\n",
      "Losses {'ner': 3621.353506088257}\n",
      "Losses {'ner': 3509.9469861984253}\n",
      "Losses {'ner': 3641.872401237488}\n",
      "Losses {'ner': 3851.946364402771}\n",
      "Losses {'ner': 3386.7536191940308}\n"
     ]
    }
   ],
   "source": [
    "# Importing requirements\n",
    "from spacy.util import minibatch, compounding\n",
    "import random\n",
    "\n",
    "# Begin training by disabling other pipeline components\n",
    "with nlp.disable_pipes(*other_pipes) :\n",
    "    sizes = compounding(1.0, 4.0, 1.001)\n",
    "    # Training for 30 iterations     \n",
    "    for itn in range(200):\n",
    "        # shuffle examples before training\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        batches = minibatch(TRAIN_DATA, size=sizes)\n",
    "        # ictionary to store losses\n",
    "        losses = {}\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            # Calling update() over the iteration\n",
    "            nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
    "        if itn%10==0:\n",
    "            print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_DATA[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('Mr. T.RADHA KRISHNAN', '[partyone]'), ('Mr.', '[partytwo]'), ('11 months', '[duration]')]\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "doc = nlp(TRAIN_DATA[7][0])\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "# print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents if ent.label_ in ['[start]', '[partyone]', '[partytwo]', '[rent]', '[end]', '[duration]', '{{', \"}}\"] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)\n",
    "\n",
    "# # Save and load\n",
    "# # Save the  model to directory\n",
    "# output_dir = Path('/content/')\n",
    "# nlp.to_disk(output_dir)\n",
    "# print(\"Saved model to\", output_dir)\n",
    "\n",
    "# # Load the saved model and predict\n",
    "# print(\"Loading from\", output_dir)\n",
    "# nlp_updated = spacy.load(output_dir)\n",
    "# doc = nlp_updated(\"Fridge can be ordered in FlipKart\" )\n",
    "# print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training blank Spacy NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train NER from a blank spacy model\n",
    "import spacy\n",
    "\n",
    "nlp=spacy.blank(\"en\")\n",
    "\n",
    "nlp.add_pipe(nlp.create_pipe('ner'))\n",
    "\n",
    "nlp.begin_training()\n",
    "\n",
    "# Getting the pipeline component\n",
    "ner=nlp.get_pipe(\"ner\")\n",
    "\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])\n",
    "    \n",
    "# Disable pipeline components you dont need to change\n",
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 3205.9327850341797}\n",
      "Losses {'ner': 5528.513359069824}\n",
      "Losses {'ner': 6007.531702041626}\n",
      "Losses {'ner': 1220.990077972412}\n",
      "Losses {'ner': 2690.2003421783447}\n",
      "Losses {'ner': 2955.9251465797424}\n",
      "Losses {'ner': 1204.6117010116577}\n",
      "Losses {'ner': 2666.046299934387}\n",
      "Losses {'ner': 2921.629918396473}\n",
      "Losses {'ner': 1175.2764053344727}\n",
      "Losses {'ner': 2666.9113368988037}\n",
      "Losses {'ner': 2948.899775803089}\n",
      "Losses {'ner': 1538.6098098754883}\n",
      "Losses {'ner': 2788.4858055114746}\n",
      "Losses {'ner': 3072.4911503493786}\n",
      "Losses {'ner': 1509.9055519104004}\n",
      "Losses {'ner': 2730.203866958618}\n",
      "Losses {'ner': 3057.774088859558}\n",
      "Losses {'ner': 1524.9072875976562}\n",
      "Losses {'ner': 2693.213598251343}\n",
      "Losses {'ner': 3061.1789159994696}\n",
      "Losses {'ner': 1532.1764793395996}\n",
      "Losses {'ner': 2703.2969522476196}\n",
      "Losses {'ner': 2981.657818675041}\n",
      "Losses {'ner': 1508.3323516845703}\n",
      "Losses {'ner': 2753.537094116211}\n",
      "Losses {'ner': 3035.1302840709686}\n",
      "Losses {'ner': 1123.8154640197754}\n",
      "Losses {'ner': 2692.2119007110596}\n",
      "Losses {'ner': 2962.511127471924}\n",
      "Losses {'ner': 1493.7244777679443}\n",
      "Losses {'ner': 2676.0109519958496}\n",
      "Losses {'ner': 3019.0905318260193}\n",
      "Losses {'ner': 1290.5532655715942}\n",
      "Losses {'ner': 2719.21475315094}\n",
      "Losses {'ner': 3008.412220478058}\n",
      "Losses {'ner': 1230.295922279358}\n",
      "Losses {'ner': 2680.337224006653}\n",
      "Losses {'ner': 3007.928295612335}\n",
      "Losses {'ner': 1496.5116081237793}\n",
      "Losses {'ner': 2727.724443435669}\n",
      "Losses {'ner': 3039.7831275463104}\n",
      "Losses {'ner': 1585.7541246414185}\n",
      "Losses {'ner': 2798.5356225967407}\n",
      "Losses {'ner': 3108.026410281658}\n",
      "Losses {'ner': 1174.657382965088}\n",
      "Losses {'ner': 2702.7484827041626}\n",
      "Losses {'ner': 3020.134434223175}\n",
      "Losses {'ner': 1534.9932460784912}\n",
      "Losses {'ner': 2696.3374996185303}\n",
      "Losses {'ner': 3017.1330956816673}\n",
      "Losses {'ner': 1167.5763835906982}\n",
      "Losses {'ner': 2739.400155067444}\n",
      "Losses {'ner': 3070.5993790626526}\n",
      "Losses {'ner': 1433.2863159179688}\n",
      "Losses {'ner': 2714.7200870513916}\n",
      "Losses {'ner': 3064.5934929847717}\n",
      "Losses {'ner': 1176.7441711425781}\n",
      "Losses {'ner': 2682.7021255493164}\n",
      "Losses {'ner': 2964.6781842708588}\n"
     ]
    }
   ],
   "source": [
    "# Import requirements\n",
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from pathlib import Path\n",
    "\n",
    "# TRAINING THE MODEL\n",
    "with nlp.disable_pipes(*unaffected_pipes):\n",
    "\n",
    "  # Training for 30 iterations\n",
    "  for iteration in range(200):\n",
    "\n",
    "    # shuufling examples  before every iteration\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    losses = {}\n",
    "    # batch up the examples using spaCy's minibatch\n",
    "    batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "    for batch in batches:\n",
    "        texts, annotations = zip(*batch)\n",
    "        nlp.update(\n",
    "                    texts,  # batch of texts\n",
    "                    annotations,  # batch of annotations\n",
    "                    drop=0.5,  # dropout - make it harder to memorise data\n",
    "                    losses=losses,\n",
    "                )\n",
    "        if iteration%10==0:\n",
    "            print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('1st day of February 2008, by and between\\n\\n', '[start]'), ('Mr. T.RADHA KRISHNAN\\n\\nNo-57,1st', '[partyone]'), ('Mr.AIilllJIT', '[partytwo]')]\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "doc = nlp(TRAIN_DATA[6][0])\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "# print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents if ent.label_ in ['[start]', '[partyone]', '[partytwo]', '[rent]', '[end]', '[duration]', '{{', \"}}\"] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRENTAL AGREEMENT\\n\\nThis Agreement of Tenancy is made and executed at Bangalore, on this the 1st day of February 2008, by and between\\n\\nMr. T.RADHA KRISHNAN\\n\\nNo-57,1st floor,’’Hemalaya”, Golf view layout Murugeshpalya, Bangalore-17\\n\\nHereinafter referred to as the OWNER of the one part, and\\n\\nMr.AIilllJIT BHARADWAJ\\n\\nC/oS.R.S.Sharath, No-401\\n\\nShri ram shankari Apt, Banashankari\\n\\n3rd stage, Kathiguppe, Bangalore-85\\n\\nPh-080-26727961\\n\\nMobile: 9886463146\\n\\nWorking for i2 Technologies India Pvt, Ltd. #132/133, Divya sree Technopolis, Yamalur post, off airport Road, Bangalore-37\\n\\nHereinafter referred to as the TENANT of the Other Part.\\n\\nConsideration of the rent hereinafter reserved and the conditions hereinafter stated.\\n\\nNOW THIS AGREEMENT WITNESSETH AS FOLLOWS:\\n\\n\\tThe tenant shall pay a monthly rent of Rs.3,500/-(Rupees Three Thousand Five Hundred Only) on or before 5th of every month. Including Maintenance charges (water& Electricity).\\n\\n\\tThe tenant has deposited with owner Rs.20,000/- (Rupees Twenty Thousand Only) by way of Cash, as advance and security deposit which sum the owner hereby acknowledges. The said sum shall carry no interest but refundable to the tenant on the termination of the tenancy.\\n\\n\\tThe tenancy shall be in force for a period of Eleven Months commencing from 1st day of February 2008, and the month of tenancy being the English calendar month.\\n\\n\\tThe owner shall have the right to terminate the tenancy if the tenant fails to pay the rents regularly for a consecutive period of three months commits breach of any of the terms herein and take possession of the residence.\\n\\n\\tThe tenant shall use the premises only for Residential purpose and shall not use it for any offensive or objectionable purpose and shall not without the written consent of the owner sublet under lease or part with the possession of the premises any whosoever or make any alterations therein. He shall return possession of the house in as such condition as it was let out to him save normal wear and tear and shall allow the owner or his authorized agent to inspect the house at all reasonable times but with prior intimation.\\n\\n\\tThe owner shall allow the tenant peaceful possession and enjoyment of the premises during the continuance of the tenancy provided the tenant acts up to the terms of this agreement.\\n\\n\\tThe owner shall pay property taxes.\\n\\n\\tThe tenancy may be renewed for further period /s mutually agrees between the parties on the terms and conditions to be specified at the time.\\n\\n\\tIt is hereby agreed that One month[notice] notice on either side is required for the termination of the tenancy.\\n\\n\\tThe tenant shall not cause any damage to fixed fixtures and fittings of the above said property the tenant should return back the premises in good condition, as it let out any damages caused owner have right to deduct the amount.\\n\\n\\tAfter the expiry of 11 months the tenant is herein agreed to pay 5% of enhancement of the existing rent.\\n\\nSCI!I I)I I I\\n\\nThe premises at No-57,2nd floor,’’Hemalaya”, Golf view layout, Murugeshpalya, Bangalore-17\\n\\n\\tPremises Consist of Single room, Attached Bathroom & Toilet, two wheeler parking having a super built up area of\\tsq.ft.\\n\\nFittings Fan -1 Nos, Tube lights -1 Nos, Bulps-2 Nos.\\n\\nIN WITNESS WHEREOF, the parties have set their respective hand unto this agreement, the day, month, year first above written.\\n\\nWITNESS:\\n\\n1. Jagdish\\n\\nBangalore Homes\\n\\n\\tNo.5, RifcoSanthosh Apartments\\t(OWNER)\\n\\nNAL Road, Murugeshpalya Bangalore-560017\\n\\nPH-9844495539', 9845444484\\n\\n2. Babu\\n\\n9448030266\\n\\n(TENANT)\""
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA[6][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare test data and run model to generate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_result = []\n",
    "for file in glob(\"../data/Validation_Data/*\"):\n",
    "    # read and convert the doc to text\n",
    "    text = docxpy.process(file)\n",
    "    # extract entities\n",
    "    doc = nlp(text)\n",
    "    result = {ent.label_:ent.text for ent in doc.ents}\n",
    "    result['file_name'] = file\n",
    "    # save them to df\n",
    "    validation_result.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>[start]</th>\n",
       "      <th>[partyone]</th>\n",
       "      <th>[partytwo]</th>\n",
       "      <th>[duration]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/Validation_Data\\156155545-Rental-Agree...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/Validation_Data\\195231682-This-RENTAL-...</td>\n",
       "      <td>06th day of March 2013 at Hyderabad. By and be...</td>\n",
       "      <td>C.BHAGYAMMA</td>\n",
       "      <td>JP INTERIO</td>\n",
       "      <td>11 months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/Validation_Data\\228094620-Rental-Agree...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eleven months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/Validation_Data\\239419594-Rental-Agree...</td>\n",
       "      <td>17th day of July two thousand\\n\\nforteen</td>\n",
       "      <td>Mr. SIMON PA</td>\n",
       "      <td>Mr. VAIRAVAN A</td>\n",
       "      <td>11 months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/Validation_Data\\24158401-Rental-Agreem...</td>\n",
       "      <td>1st day of April 2008 (1-04-08) by and between...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12 months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>../data/Validation_Data\\269135973-Udaya-Rental...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>../data/Validation_Data\\63793679-Rental-Agreem...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eleven months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>../data/Validation_Data\\95980236-Rental-Agreem...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_name  \\\n",
       "0  ../data/Validation_Data\\156155545-Rental-Agree...   \n",
       "1  ../data/Validation_Data\\195231682-This-RENTAL-...   \n",
       "2  ../data/Validation_Data\\228094620-Rental-Agree...   \n",
       "3  ../data/Validation_Data\\239419594-Rental-Agree...   \n",
       "4  ../data/Validation_Data\\24158401-Rental-Agreem...   \n",
       "5  ../data/Validation_Data\\269135973-Udaya-Rental...   \n",
       "6  ../data/Validation_Data\\63793679-Rental-Agreem...   \n",
       "7  ../data/Validation_Data\\95980236-Rental-Agreem...   \n",
       "\n",
       "                                             [start]    [partyone]  \\\n",
       "0                                                NaN           NaN   \n",
       "1  06th day of March 2013 at Hyderabad. By and be...   C.BHAGYAMMA   \n",
       "2                                                NaN           NaN   \n",
       "3           17th day of July two thousand\\n\\nforteen  Mr. SIMON PA   \n",
       "4  1st day of April 2008 (1-04-08) by and between...           NaN   \n",
       "5                                                NaN           NaN   \n",
       "6                                                NaN           Mr.   \n",
       "7                                                NaN           NaN   \n",
       "\n",
       "       [partytwo]     [duration]  \n",
       "0             NaN            NaN  \n",
       "1      JP INTERIO      11 months  \n",
       "2             NaN  eleven months  \n",
       "3  Mr. VAIRAVAN A      11 months  \n",
       "4             NaN      12 months  \n",
       "5             NaN            NaN  \n",
       "6             NaN  eleven months  \n",
       "7             NaN            NaN  "
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(validation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlap between training and test set -- we ignore these files while testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'195231682-This-RENTAL-AGREEMENT-is-Made-and-Executed-on-24th-Day-of-September.pdf.docx',\n",
       " '269135973-Udaya-Rental-Agreement.pdf.docx',\n",
       " '63793679-Rental-Agreement.pdf.docx',\n",
       " '95980236-Rental-Agreement.pdf.docx'}"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfiles = [x[22:] for x in glob(\"../data/Training_data/*\")]\n",
    "vfiles = [x[24:] for x in glob(\"../data/Validation_Data/*\")]\n",
    "set(tfiles) & set(vfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['156155545-Rental-Agreement-Kns-Home.pdf.docx',\n",
       " '195231682-This-RENTAL-AGREEMENT-is-Made-and-Executed-on-24th-Day-of-September.pdf.docx',\n",
       " '228094620-Rental-Agreement.pdf.docx',\n",
       " '239419594-Rental-Agreement.pdf.docx',\n",
       " '24158401-Rental-Agreement.pdf.docx',\n",
       " '269135973-Udaya-Rental-Agreement.pdf.docx',\n",
       " '63793679-Rental-Agreement.pdf.docx',\n",
       " '95980236-Rental-Agreement.pdf.docx']"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
